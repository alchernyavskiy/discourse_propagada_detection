{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct datasets in cycle (+for ablation study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alchernyavskiy/anaconda3/envs/py37deberta/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glue_deberta.dataset_construction import construct_semeval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 446/446 [00:00<00:00, 1679.68it/s]\n",
      "100%|█████████████████████████████████████████| 446/446 [00:48<00:00,  9.24it/s]\n",
      "100%|█████████████████████████████████████| 9498/9498 [00:07<00:00, 1298.76it/s]\n",
      "100%|█████████████████████████████████████████| 90/90 [00:00<00:00, 1183.51it/s]\n",
      "100%|███████████████████████████████████████████| 90/90 [00:04<00:00, 18.99it/s]\n",
      "100%|█████████████████████████████████████| 3127/3127 [00:00<00:00, 4245.14it/s]\n",
      "100%|█████████████████████████████████████████| 54/54 [00:00<00:00, 1744.62it/s]\n",
      "100%|███████████████████████████████████████████| 54/54 [00:02<00:00, 21.48it/s]\n",
      "100%|███████████████████████████████████████| 910/910 [00:00<00:00, 5376.18it/s]\n"
     ]
    }
   ],
   "source": [
    "disco_depth = 2\n",
    "options = [\n",
    "    [True, True, True],\n",
    "    [True, True, False],\n",
    "    [True, False, False],\n",
    "    [False, False, False]\n",
    "]\n",
    "\n",
    "for part in ['train', 'dev', 'test']: \n",
    "    for (use_nucsat, use_rels, use_paths) in options:\n",
    "        construct_semeval_dataset(\n",
    "            part = part,\n",
    "            disco_depth=disco_depth,\n",
    "            use_rels=use_rels,\n",
    "            use_nucsat=use_nucsat,\n",
    "            use_paths=use_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add no-feats version to train the base model\n",
    "import json\n",
    "\n",
    "for part in ['train', 'dev', 'test']:\n",
    "    fn = f'datasets/deberta_propaganda_classif/{part}_custom_feats=2_lvl2--use_rels=False--use_nucsat=True--use_paths=False_multi.json'\n",
    "\n",
    "    with open(fn, 'r') as outfile:\n",
    "        data = json.load(outfile)\n",
    "\n",
    "    for el in data:\n",
    "        del el['feature']\n",
    "\n",
    "    with open(fn.replace('.json', '_nofeat.json'), 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save weights for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'datasets/deberta_propaganda_classif/train_custom_feats=40_lvl2--use_rels=True--use_nucsat=True--use_paths=True_multi.json', 'r') as outfile:\n",
    "    data_train = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'article111111111.txt',\n",
       " 'sentence1': 'But Tedros voiced alarm that \"plague in Madagascar behaved in a very, very different way this year.\"',\n",
       " 'label': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'i': 13,\n",
       " 'span': [1006, 1107],\n",
       " 'feature': [0.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights =  []\n",
    "for i in range(len(data_train[0]['label'])):\n",
    "    label_vals = [] \n",
    "    for item in data_train:\n",
    "        label_vals.append(item['label'][i])\n",
    "    num_pos = max(sum(label_vals), 1)\n",
    "    num_neg = len(label_vals) - num_pos\n",
    "    weights.append(min(70, num_neg / num_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.675324675324674,\n",
       " 29.638709677419357,\n",
       " 70,\n",
       " 70,\n",
       " 43.59154929577465,\n",
       " 70,\n",
       " 17.335907335907336,\n",
       " 19.38197424892704,\n",
       " 70,\n",
       " 32.09407665505226,\n",
       " 70,\n",
       " 4.250414593698176,\n",
       " 8.70173646578141,\n",
       " 70,\n",
       " 70,\n",
       " 16.459558823529413,\n",
       " 61.07843137254902,\n",
       " 70,\n",
       " 70]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glue_deberta/pos_weights.pkl', 'wb') as f:\n",
    "    pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glue_deberta/pos_weights.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = ['Appeal_to_Authority',\n",
    " 'Appeal_to_Fear-Prejudice',\n",
    " 'Appeal_to_Hypocrisy',\n",
    " 'Appeal_to_Popularity',\n",
    " 'Causal_Oversimplification',\n",
    " 'Conversation_Killer',\n",
    " 'Doubt',\n",
    " 'Exaggeration-Minimisation',\n",
    " 'False_Dilemma-No_Choice',\n",
    " 'Flag_Waving',\n",
    " 'Guilt_by_Association',\n",
    " 'Loaded_Language',\n",
    " 'Name_Calling-Labeling',\n",
    " 'Obfuscation-Vagueness-Confusion',\n",
    " 'Red_Herring',\n",
    " 'Repetition',\n",
    " 'Slogans',\n",
    " 'Straw_Man',\n",
    " 'Whataboutism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Appeal_to_Authority', 60.675324675324674),\n",
       " ('Appeal_to_Fear-Prejudice', 29.638709677419357),\n",
       " ('Appeal_to_Hypocrisy', 70),\n",
       " ('Appeal_to_Popularity', 70),\n",
       " ('Causal_Oversimplification', 43.59154929577465),\n",
       " ('Conversation_Killer', 70),\n",
       " ('Doubt', 17.335907335907336),\n",
       " ('Exaggeration-Minimisation', 19.38197424892704),\n",
       " ('False_Dilemma-No_Choice', 70),\n",
       " ('Flag_Waving', 32.09407665505226),\n",
       " ('Guilt_by_Association', 70),\n",
       " ('Loaded_Language', 4.250414593698176),\n",
       " ('Name_Calling-Labeling', 8.70173646578141),\n",
       " ('Obfuscation-Vagueness-Confusion', 70),\n",
       " ('Red_Herring', 70),\n",
       " ('Repetition', 16.459558823529413),\n",
       " ('Slogans', 61.07843137254902),\n",
       " ('Straw_Man', 70),\n",
       " ('Whataboutism', 70)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(labels_list, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN BASE\n",
    "#--label_all_tokens    checkpointing_steps 'epoch' 10000; 2 -- extra_feature_size=42 2e-5\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python glue_deberta/run_glue_no_trainer.py \\\n",
    "  --model_name_or_path \"microsoft/deberta-v3-base\" \\\n",
    "  --train_file 'datasets/deberta_propaganda_classif/train_custom_feats=2_lvl2--use_rels=False--use_nucsat=True--use_paths=False_multi_nofeat.json' \\\n",
    "  --validation_file 'datasets/deberta_propaganda_classif/dev_custom_feats=2_lvl2--use_rels=False--use_nucsat=True--use_paths=False_multi_nofeat.json' \\\n",
    "  --max_length 256 \\\n",
    "  --pad_to_max_length \\\n",
    "  --per_device_train_batch_size 2 \\\n",
    "  --per_device_eval_batch_size 2 \\\n",
    "  --gradient_accumulation_steps 8 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 45 \\\n",
    "  --checkpointing_steps 100000 \\\n",
    "  --output_dir \"checkpoint_cls/deberta_glue_binary_noo_lr3e-5-16-45ep_w70_2lin__base\" \\\n",
    "  --with_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run custom model training in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glue_deberta.train_loop import run_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "     [True, True, True],\n",
    "     [True, True, False],\n",
    "    [True, False, False],\n",
    "   [False, False, False]\n",
    "]\n",
    "\n",
    "for (use_nucsat, use_rels, use_paths) in options:\n",
    "    run_train(level=2,\n",
    "              lr=2e-5,\n",
    "              bs=8,\n",
    "              gac=2,\n",
    "              n_epochs=45,\n",
    "              use_rels=use_rels,\n",
    "              use_nucsat=use_nucsat,\n",
    "              use_paths=use_paths,\n",
    "              save_eval_metric='micro_f1',\n",
    "              device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(0, 'glue_deberta/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alchernyavskiy/anaconda3/envs/py37deberta/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from inference import run_inference"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name_or_path =  \"checkpoint_cls/deberta_glue_binary_noo_lr2e-05-8-45ep_w70_2lin__lvl2--use_rels=True--use_nucsat=True--use_paths=True_multi\"\n",
    "dev_json = 'datasets/deberta_propaganda_classif/train_custom_feats=40_lvl2--use_rels=True--use_nucsat=True--use_paths=True_multi.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'checkpoint_cls/deberta_glue_binary_noo_lr2e-05-8-45ep_w70_2lin__lvl2--use_rels=True--use_nucsat=True--use_paths=True_multi'\n",
    "\n",
    "for fn in os.listdir('datasets/deberta_propaganda_classif/'):\n",
    "    if fn.endswith(model_name_or_path.split('--', 1)[1] + '.json') and fn.startswith('test'):\n",
    "        dev_json = 'datasets/deberta_propaganda_classif/' + fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/alchernyavskiy/.cache/huggingface/datasets/json/default-c355148cc7e87df9/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 316.86it/s]\n",
      "Loading cached processed dataset at /home/alchernyavskiy/.cache/huggingface/datasets/json/default-c355148cc7e87df9/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1bce466a3bd3eff.arrow\n",
      "114it [00:11, 10.13it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = run_inference(model_name_or_path, dev_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions/test_predictions_lvl2_disco.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path =  \"checkpoint_cls/deberta_glue_binary_noo_lr3e-5-16-45ep_w70_2lin__base/\"\n",
    "dev_json = 'datasets/deberta_propaganda_classif/test_custom_feats=2_lvl2--use_rels=False--use_nucsat=True--use_paths=False_multi_nofeat.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/alchernyavskiy/.cache/huggingface/datasets/json/default-589407286ff21d76/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████| 1/1 [00:00<00:00, 925.89it/s]\n",
      "Extracting data files: 100%|██████████████████████| 1/1 [00:00<00:00, 87.67it/s]\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/alchernyavskiy/.cache/huggingface/datasets/json/default-589407286ff21d76/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 406.39it/s]\n",
      "114it [00:11, 10.16it/s]                                                        \n"
     ]
    }
   ],
   "source": [
    "preds = run_inference(model_name_or_path, dev_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions/test_predictions_lvl2_base.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = ['Loaded_Language',\n",
    " 'Name_Calling-Labeling',\n",
    " 'Repetition',\n",
    " 'Exaggeration-Minimisation',\n",
    " 'Doubt',\n",
    " 'Appeal_to_Fear-Prejudice',\n",
    " 'Flag_Waving',\n",
    " 'Causal_Oversimplification',\n",
    " 'Slogans',\n",
    " 'Appeal_to_Authority',\n",
    " 'False_Dilemma-No_Choice',\n",
    " 'Conversation_Killer',\n",
    " 'Guilt_by_Association',\n",
    " 'Red_Herring',\n",
    " 'Appeal_to_Hypocrisy',\n",
    " 'Whataboutism',\n",
    " 'Obfuscation-Vagueness-Confusion',\n",
    " 'Appeal_to_Popularity',\n",
    " 'Straw_Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = sorted(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/deberta_propaganda_classif/test_custom_feats=40_lvl2--use_rels=True--use_nucsat=True--use_paths=True_multi.json', 'r') as f:\n",
    "    labels = []\n",
    "    labels_data = json.load(f)\n",
    "    for lab_list in labels_data:\n",
    "        lab_list = lab_list['label']\n",
    "        lab_names = [label_list[i] for i in range(len(lab_list)) if lab_list[i] == 1.]\n",
    "        labels.append(lab_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions/test_predictions_lvl2_base.pkl\", \"rb\") as f:\n",
    "    preds_base = pickle.load(f)\n",
    "    \n",
    "with open(\"predictions/test_predictions_lvl2_disco.pkl\", \"rb\") as f:\n",
    "    preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = [714, 535, 350, 329, 266, 211, 144, 118, 115, 94, 66, 43, 37, 34, 16, 15, 13, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, cnt in zip(labels_list, cnts):\n",
    "    lab_true = [1 if lab in elem else 0 for elem in labels]\n",
    "    lab_pred = [1 if lab in elem else 0 for elem in preds]\n",
    "    lab_pred_base = [1 if lab in elem else 0 for elem in preds_base]\n",
    "    if sum(lab_true) > 0:\n",
    "        prec, rec, f1 = precision_score(lab_true, lab_pred), recall_score(lab_true, lab_pred), f1_score(lab_true, lab_pred)\n",
    "        prec_b, rec_b, f1_b = precision_score(lab_true, lab_pred_base), recall_score(lab_true, lab_pred_base),\\\n",
    "                f1_score(lab_true, lab_pred_base)\n",
    "        print(lab, round(100 * cnt / sum(cnts), 2))\n",
    "        print(f'DISCO. Precision: {round(prec, 3)}; Recall {round(rec, 3)}; F1: {round(f1, 3)}')\n",
    "        print(f'BASE. Precision: {round(prec_b, 3)}; Recall {round(rec_b, 3)}; F1: {round(f1_b, 3)}')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predicted_tags, labels):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([labels_list])\n",
    "\n",
    "    predicted_tags_noo, labels_noo = [], []\n",
    "    for lab, pr in zip(predicted_tags, labels):\n",
    "        predicted_tags_noo.append([p for p in pr if p != 'O'])\n",
    "        labels_noo.append([p for p in lab if p != 'O'])\n",
    "\n",
    "    gold_values = mlb.transform(labels_noo)\n",
    "    pred_values = mlb.transform(predicted_tags_noo)\n",
    "\n",
    "    return {\n",
    "        \"macro_f1\": f1_score(gold_values, pred_values, average=\"macro\", zero_division=1),\n",
    "        \"micro_f1\": f1_score(gold_values, pred_values, average=\"micro\", zero_division=1),\n",
    "        \"accuracy\": np.mean(np.all(gold_values == pred_values, axis=1))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_f1': 0.1706033347274226,\n",
       " 'micro_f1': 0.3884758364312268,\n",
       " 'accuracy': 0.29010989010989013}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_f1': 0.1593540498453423,\n",
       " 'micro_f1': 0.3169726489321843,\n",
       " 'accuracy': 0.22747252747252747}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(preds_base, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37deberta",
   "language": "python",
   "name": "py37deberta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
